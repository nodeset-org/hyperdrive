# Default Prometheus configuration for Hyperdrive

global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  scrape_timeout:      12s # Timeout must be shorter than the interval
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:{{or .Hyperdrive.Metrics.Prometheus.Port.Value "9091"}}']

  - job_name: 'node'
    static_configs:
      # node-exporter is on the host network so it can get access to the actual machine's network info
      # We have to use 'hosts.docker.internal' to refer to it due to this configuration
      - targets: ['host.docker.internal:{{or .Hyperdrive.Metrics.ExporterMetricsPort.Value "9103"}}']

  - job_name: '{{if (eq .Hyperdrive.GetSelectedExecutionClient "geth")}}geth{{else}}{{.Hyperdrive.ExecutionClientContainerName}}{{end}}'
    static_configs:
      - targets: ['{{.Hyperdrive.GetExecutionHostname}}:{{or .Hyperdrive.Metrics.EcMetricsPort.Value "9105"}}']
    {{- if (eq .Hyperdrive.GetSelectedExecutionClient "geth")}}
    metrics_path: /debug/metrics/prometheus
    {{- end}}

  - job_name: '{{.Hyperdrive.BeaconNodeContainerName}}'
    static_configs:
      - targets: ['{{.Hyperdrive.GetBeaconHostname}}:{{or .Hyperdrive.Metrics.BnMetricsPort.Value "9100"}}']

  - job_name: 'hyperdrive'
    scrape_interval: 5m
    scrape_timeout: 5m
    static_configs:
      - targets: ['{{.Hyperdrive.DaemonContainerName}}:{{or .Hyperdrive.Metrics.DaemonMetricsPort.Value "9102"}}']

  - job_name: 'custom_jobs' # Mandatory field, but will be ignored.
    file_sd_configs:
      - files:
        - /extra-scrape-jobs/*.yml
